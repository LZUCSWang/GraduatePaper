% filepath: /home/stu_wxy/DL-DRL-new/lower/grp_model_algorithm.tex
\documentclass[10pt,a4paper]{article}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{hyperref}

\title{GRP问题的注意力模型架构与训练算法}
\author{AI Assistant}
\date{\today}

\begin{document}

\maketitle

\section{GRP问题模型架构概述}

本文档描述了用于解决绿色路径规划(Green Routing Problem, GRP)问题的注意力模型架构与训练算法。GRP问题是一个组合优化问题，需要考虑路径规划和区域修复决策。

\section{模型架构}

GRP问题的注意力模型主要由以下组件构成：

\begin{enumerate}
    \item \textbf{输入层}：处理节点特征 (x, y, degradation, area)
    \item \textbf{Graph Attention 编码器}：
        \begin{itemize}
            \item 初始嵌入层：将输入特征映射到嵌入空间
            \item 多头自注意力层：处理节点间关系
            \item 输出节点嵌入和图嵌入
        \end{itemize}
    \item \textbf{注意力解码器}：
        \begin{itemize}
            \item 上下文投影层
            \item 多头注意力机制 (Glimpse + Pointer)
            \item 生成节点访问序列
        \end{itemize}
    \item \textbf{GRP特有组件}：
        \begin{itemize}
            \item 修复面积预测网络：预测每个节点的修复量
            \item 奖励计算：基于路径长度和修复面积计算总奖励
        \end{itemize}
\end{enumerate}

\section{训练算法}

以下是GRP问题的注意力模型训练算法的伪代码：

\begin{algorithm}[h]
    \begin{algorithmic}[1]
        \caption{GRP问题的注意力模型训练算法} \label{alg:grp_training}
        \Require 注意力模型参数 $\theta$，嵌入维度 $d_e$，隐藏层维度 $d_h$，编码器层数 $n_{layers}$，注意力头数 $n_{heads}$，学习率 $\alpha$，训练轮数 $N_{epoch}$，批次大小 $B$，图大小 $G_{size}$，baseline类型 $B_{type}$
        \Ensure 训练好的模型参数 $\theta^*$

        \State 初始化注意力模型及其参数 $\theta$
        \State 初始化baseline模型 $B_{model}$ (可选：NoBaseline, ExponentialBaseline, CriticBaseline, RolloutBaseline)
        \State 初始化优化器 Adam，学习率为 $\alpha$
        \State 初始化学习率调度器 LR\_Scheduler
        \State 生成验证数据集 $val\_set$ (大小为 $val\_size$)
        
        \For{$epoch = 0$ to $N_{epoch} - 1$}
            \State 生成或包装训练数据集 $train\_set$ (大小为 $epoch\_size$)
            \State 将 $train\_set$ 分为大小为 $B$ 的批次
            \State 设置模型为训练模式
            \State 设置解码类型为 "sampling"
            
            \For{每个批次 $batch$ in $train\_set$}
                \State 从 $batch$ 中提取输入数据 $x$ 和baseline值 $bl\_val$
                \State 将数据移至指定设备(CPU/GPU)
                
                \State \textcolor{blue}{// 前向传播}
                \State $cost, log\_likelihood \leftarrow model(x)$
                \State $reward \leftarrow -cost$
                
                \State \textcolor{blue}{// 对于GRP问题，分别记录修复面积}
                \If{问题类型为 "grp"}
                    \State 提取或计算总修复面积 $repair\_area$
                \EndIf
                
                \State \textcolor{blue}{// 评估baseline值}
                \If{$bl\_val$ 为 None}
                    \State $bl\_val, bl\_loss \leftarrow baseline.eval(x, cost)$
                \Else
                    \State $bl\_loss \leftarrow 0$
                \EndIf
                
                \State \textcolor{blue}{// 计算REINFORCE算法损失}
                \State $reinforce\_loss \leftarrow ((cost - bl\_val) \cdot log\_likelihood).mean()$
                \State $loss \leftarrow reinforce\_loss + bl\_loss$
                
                \State \textcolor{blue}{// 反向传播和参数更新}
                \State 清空优化器梯度
                \State 反向传播计算梯度
                \State 对梯度进行裁剪，防止梯度爆炸
                \State 检查并修复NaN或Inf梯度
                \State 更新模型参数
                
                \State \textcolor{blue}{// 记录训练信息}
                \If{需要记录日志}
                    \State 记录损失、奖励、梯度等信息
                \EndIf
            \EndFor
            
            \State \textcolor{blue}{// 验证}
            \State 设置解码类型为 "greedy"
            \State 设置模型为评估模式
            \State 在 $val\_dataset$ 上计算验证成本 $val\_cost$
            \State $avg\_reward \leftarrow -val\_cost.mean()$
            
            \State \textcolor{blue}{// Baseline更新}
            \State $baseline.epoch\_callback(model, epoch)$
            
            \State \textcolor{blue}{// 学习率更新}
            \State 调用学习率调度器更新学习率
            
            \State \textcolor{blue}{// 保存检查点}
            \If{需要保存检查点}
                \State 保存模型参数、优化器状态和其他信息
            \EndIf
            
            \State \textcolor{blue}{// 更新最佳模型}
            \If{$epoch == 0$ 或 $avg\_reward > best\_reward$}
                \State $\theta^* \leftarrow \theta$
                \State $best\_reward \leftarrow avg\_reward$
            \EndIf
        \EndFor
        
        \State \Return $\theta^*$
    \end{algorithmic}
\end{algorithm}

\section{GRP问题特有组件}

在常规的注意力模型基础上，GRP问题引入了以下特有组件：

\subsection{修复面积预测网络}
该网络是一个三层MLP结构，用于预测每个节点的修复量：
\begin{verbatim}
self.repair_prediction = nn.Sequential(
    nn.Linear(embedding_dim, hidden_dim),
    nn.ReLU(),
    nn.Dropout(0.1),            
    nn.Linear(hidden_dim, hidden_dim // 2),
    nn.ReLU(),
    nn.Dropout(0.1),
    nn.Linear(hidden_dim // 2, 1)
)
\end{verbatim}

\subsection{输入特征}
GRP问题的节点特征包括：
\begin{itemize}
    \item (x, y): 节点坐标
    \item degradation: 区域退化度
    \item area: 区域面积
\end{itemize}

\subsection{状态表示}
GRP问题的状态表示包含节点嵌入和剩余能量信息：
\begin{verbatim}
step_context_dim = embedding_dim + 1  # 节点嵌入 + 剩余能量
\end{verbatim}

\section{总结}

GRP问题的注意力模型通过结合Transformer架构和强化学习技术，能够同时处理路径选择和修复量决策两个子问题。模型训练采用REINFORCE算法，通过多次迭代优化模型参数以最大化累计奖励。

\end{document}